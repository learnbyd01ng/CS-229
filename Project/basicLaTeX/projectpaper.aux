\relax 
\@writefile{toc}{\contentsline {section}{\numberline {I}Introduction}{1}}
\@writefile{toc}{\contentsline {section}{\numberline {II}Related Work}{1}}
\@writefile{toc}{\contentsline {section}{\numberline {III}Dataset and Features}{1}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Feature Set\relax }}{1}}
\@writefile{toc}{\contentsline {section}{\numberline {IV}Methods}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {I}Random Forests}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {II}Hidden Markov Models}{2}}
\newlabel{eq:hmmLimited}{{1}{2}}
\newlabel{eq:hmmStationary}{{2}{2}}
\newlabel{eq:hmmlaplace}{{3}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {III}Recurrent Neural Networks}{2}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{eq:backprop}{{4}{3}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces An example recurrent neural network. Outputs from the hidden layer neurons from the previous time step are fed back in as input to the next time step.\relax }}{3}}
\newlabel{fig:RNNExample}{{1}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {IV}Gradient Boosting Regression}{3}}
\@writefile{toc}{\contentsline {section}{\numberline {V}Results and Discussion}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {I}Random Forest}{3}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Parameter Selection for Random Forest Regression\relax }}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {II}Hidden Markov Model}{4}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces HMM error using Laplace Smoothing\relax }}{4}}
\newlabel{fig:hmmSmooth}{{2}{4}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces HMM error using Laplace Smoothing and month data\relax }}{4}}
\newlabel{fig:hmmSmoothMonth}{{3}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {III}Recurrent Neural Network}{4}}
\bibcite{Figueredo:2009dg}{1}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces RNN Error averages of different number of hidden neurons (closed days forces to 0).\relax }}{5}}
\newlabel{fig:RNNErrorForceZero}{{4}{5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {IV}Gradient Boosting}{5}}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces Model Performance\relax }}{5}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Learning Curve for 5000 tree model\relax }}{5}}
\newlabel{fig:LearningCurve}{{5}{5}}
\@writefile{lot}{\contentsline {table}{\numberline {4}{\ignorespaces Model Performance\relax }}{5}}
\@writefile{toc}{\contentsline {section}{\numberline {VI}Conclusion}{5}}
\bibcite{Liaw:2002}{2}
\bibcite{Friedman}{3}
\bibcite{Friedman2}{4}
\bibcite{Samarasinghe}{5}
\bibcite{Zucchini}{6}
